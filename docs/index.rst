.. Strands Documentation documentation master file, created by
   sphinx-quickstart on Wed Apr 26 15:38:50 2017.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

Welcome to STRANDS documentation!
=================================================

STRANDS Project
---------------

This is the main documentation for the Spatio-Temporal Representation and
Activities for Cognitive Control in Long-Term Scenarios (STRANDS) project.

Introduction
------------

STRANDS will produce intelligent mobile robots that are able to run for months
in dynamic human environments. We will provide robots with the longevity and
behavioural robustness necessary to make them truly useful assistants in a wide
range of domains. Such long-lived robots will be able to learn from a wider
range of experiences than has previously been possible, creating a whole new
generation of autonomous systems able to extract and exploit the structure in
their worlds.

Our approach is based on understanding 3D space and how it changes over time,
from milliseconds to months. We will develop novel approaches to extract
spatio-temporal structure from sensor data gathered during months of autonomous
operation. Extracted structure will include reoccurring 3D shapes, objects,
people, and models of activity. We will also develop control mechanisms which
exploit these structures to yield adaptive behaviour in highly demanding,
realworld security and care scenarios.

STRANDS aims to enable a robot to achieve robust and intelligent behaviour in
human environments through adaptation to, and the exploitation of, long-term
experience. Our approach is based on understanding 3D space and how it changes
over time, from milliseconds to months. We will develop novel approaches to
extract quantitative and qualitative spatio-temporal structure from sensor data
gathered during months of autonomous operation. Extracted structure will include
reoccurring geometric primitives, objects, people, and models of activity. We
will also develop control mechanisms which exploit these structures to yield
adaptive behaviour in highly demanding, real-world security and care scenarios.

The spatio-temporal dynamics presented by such scenarios (e.g. humans moving,
furniture changing position, objects (re-)appearing) are largely treated as
anomalous readings by state-of-the-art robots. Errors introduced by these
readings accumulate over the lifetime of such systems, preventing many of them
from running for more than a few hours. By autonomously modelling
spatio-temporal dynamics, our robots will be able run for significantly longer
than current systems (at least 120 days by the end of the project). Long
runtimes provide previously unattainable opportunities for a robot to learn
about its world. Our systems will take these opportunities, advancing long-term
mapping, life-long learning about objects, person tracking, human activity
recognition and self-motivated behaviour generation.

We will integrate our advances into complete cognitive systems to be deployed
and evaluated at two end-user sites. The tasks these systems will perform are
impossible without long-term adaptation to spatio-temporal dynamics, yet they
are tasks demanded by early adopters of cognitive robots. We will measure our
progress by benchmarking these systems against detailed user requirements and a
range of objective criteria including measures of system runtime and autonomous
behaviour.

System Overview
---------------

The STRANDS system is formed of many packages which provide various pieces of
functionality, ranging from navigation to user interaction. A list of all
packages with a brief overview of their purpose can be found
[here](packages.md). The following sections give an overview of some of the
packages which form the core of the system.

Executive
---------

The executive controls the execution of tasks requested by users or generated by
the system itself, prioritising them using various metrics such as expected
completion time, probability of successful completion, and so on.

Navigation
----------

Navigation forms the core of the movement capabilities of robots using the
system. A topological map forms the high level navigation layer, where waypoints
are linked by edges which the robot can traverse. Over time, these edges have
expected traversal times and other measures associated with them, which can be
used to optimise the path the robot takes. 

3D mapping and vision
---------------------

3D mapping and vision are major components of the system which make use of depth
cameras to generate maps and object models to use for learning.

Getting Started
---------------

You can find a tutorial which will guide you through the initial setup process
for a STRANDS system [here](setup.md). After completing this tutorial, you
should have a computer which has ROS and STRANDS packages installed, and
can run a simulation which uses some of the basic STRANDS components.

Datasets
--------

You can find the datasets generated by the project [here](datasets).

Documentation contents
----------------------

.. toctree::
   :maxdepth: 1
   :caption: Introduction:

   setup
   packages

.. toctree::
   :maxdepth: 1
   :caption: Contents:

   datasets/index
   datasets/marathon
   datasets/auto_benchmark
   datasets/care_home
   datasets/kth_3d
   datasets/kth_lt_labels
   datasets/kth_lt_moving
   datasets/kth_lt
   datasets/marathon
   datasets/meta_rooms
   datasets/mht_rgbd
   datasets/object_presence
   datasets/people_tracks
   datasets/person_activity
   datasets/small_office
   datasets/three_d_net
   datasets/tuw
   datasets/witham_wharf   
