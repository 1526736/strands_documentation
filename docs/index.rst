.. figure:: images/strands-full-logo.png
   :alt: The STRANDS Project Logo

Welcome to STRANDS documentation!
=================================================

This site contains the documentation for the software and data produced
by the `EU STRANDS Project <http://strands-project.eu>`__. For more
information on the scientific aims of the project, please see our `IEEE
RAM overview article <https://arxiv.org/abs/1604.04384>`__ or `the
STRANDS Project website <http://strands-project.eu>`__.

The project created autonomous mobile robots which were successfully
deployed for long periods in real user environments. In the process of
this we created a great deal of open source software for AI and robotics
applications. This software is all available via [the STRANDS GitHub
organisation][https://github.com/strands-project]. This site provides a
single location where the documentation from across that organisation
can be viewed. It is also the main location for software tutorials and
guides for creating systems, and provides an entry point into using our
software for new users.

Please note that a large amount of this site is automatically generated
from our code and package documentation, so the structure is currently
not perfect. Our scripts for automatically generating this site are
available
`here <https://github.com/strands-project/strands_documentation>`__.

Getting Started
===============

If you wish to understand or reuse the full STRANDS system, you should follow
`the STRANDS system tutorial <setup.html>`__. If you want to set things up as
fast as possible, see the `quick start instructions <quick_setup.html`__. Both
of these will leave you with a system which has ROS and STRANDS packages
installed, and can run a simulation which uses some of the core STRANDS
subsystems.

Core Subsystems
===============

A STRANDS system is formed of many components which provide various
pieces of functionality, ranging from navigation to user interaction. A
list of all packages with a brief overview of their purpose can be found
`here <packages.html>`__. The following sections give a brief overview of
some of the packages which form the core of the system.

STRANDS Navigation
------------------

Navigation forms the core of the movement capabilities of robots using
the system. Our work provides a `monitored
navigation <strands_navigation/monitored_navigation/index.html>`__ system which
detects failures in navigation and triggers recovery behaviours, and a
`topological navigation <strands_navigation/topological_navigation/index.html>`__
system where navigation nodes (waypoints) are linked by edges which the
robot can traverse. Topological navigation underpins many of the other
STRANDS capabilities.

STRANDS Executive
-----------------

The STRANDS executive controls the execution of tasks requested by users
or generated by the system itself, prioritising them using various
metrics such as expected completion time, probability of successful
completion, and so on. It provides facilities for both long-term task
routines, task scheduling and task planning under uncertainty. There is
a `STRANDS Executive tutorial <planning_tutorial/index.html>`__ which covers the
main parts of the system and `an overview
document <strands_executive/index.html>`__.

Person Detection and Tracking
-----------------------------

When operating in populated spaces it is crucial to be able to detect
and track people. STRANDS produced an indoor `multi-person
tracker <strands_perception_people/perception_people_launch/index.html>`__ which
fuses and tracks upper body detections and leg detections. We also have
produced `a wheelchair and walking aid
detector <strands_perception_people/wheelchair_detector/index.html>`__.

3D Mapping and Vision
---------------------

One of the major outputs of the project is a collection of systems for
discovering and learning about objects in everyday environments. These
are collected together into the STRANDS 3D Mapping collection, described
`here <strands_3d_mapping>`__.

Semantic Object Maps (SOMa)
---------------------------

The outputs of person detection and 3D mapping are stored in our
Semantic Object Map (SOMa) which captures the information the robot
gathers over long durations in a central store which supports a range of
visualisations and queries. This is described `here <soma/index.html>`__. SOMa is
backed by our integration of `MongoDB <https://www.mongodb.org>`__ into
ROS: `MongoDB Store <mongodb_store/mongodb_store/index.html>`__.

Long-Term Data Processing (FreMEn and QSRLib)
---------------------------------------------

After data is collected in SOMa our systems process it using various
techniques. Major outputs of STRANDS include `FreMen <fremen/index.html>`__ which
provides frequency-based modelling for the temporal dimension of spatial
representations, and
`QSRLib <http://qsrlib.readthedocs.io/en/latest/>`__, a library for
generating qualitative spatial relations from sensor data.

Datasets
========

You can find the datasets generated by the project `here <datasets/index.html>`__.

Documentation contents
----------------------

.. toctree::
   :maxdepth: 1
   :caption: Introduction:

   quick_setup
   setup
   packages


.. toctree::
   :maxdepth: 1
   :caption: aaf deployment:

   Aaf simulation <aaf_deployment/aaf_simulation>
   Aaf walking group <aaf_deployment/aaf_walking_group>


.. toctree::
   :maxdepth: 1
   :caption: aaf deployment info terminal:

   Index <aaf_deployment/info_terminal/index>
   Infremen <aaf_deployment/info_terminal/infremen>


.. toctree::
   :maxdepth: 1
   :caption: aaf deployment wiki:

   Home <aaf_deployment/wiki/Home>
   Topics to log during deployments <aaf_deployment/wiki/Topics-to-log-during-deployments>


.. toctree::
   :maxdepth: 1
   :caption: annotation tool kth:

   Annotation tool <annotation_tool_kth/annotation-tool>
   Index <annotation_tool_kth/index>
   Rgbd grabber <annotation_tool_kth/rgbd_grabber>


.. toctree::
   :maxdepth: 1
   :caption: datasets:

   Auto benchmark <datasets/auto_benchmark>
   Care home <datasets/care_home>
   Index <datasets/index>
   Kth 3d <datasets/kth_3d>
   Kth lt <datasets/kth_lt>
   Kth lt labels <datasets/kth_lt_labels>
   Kth lt moving <datasets/kth_lt_moving>
   Marathon <datasets/marathon>
   Meta rooms <datasets/meta_rooms>
   Mht rgbd <datasets/mht_rgbd>
   Object presence <datasets/object_presence>
   People tracks <datasets/people_tracks>
   Person activity <datasets/person_activity>
   Small office <datasets/small_office>
   Three d net <datasets/three_d_net>
   Tuw <datasets/tuw>
   Witham wharf <datasets/witham_wharf>


.. toctree::
   :maxdepth: 1
   :caption: g4s deployment:

   Index <g4s_deployment/index>
   Tsc control ui <g4s_deployment/tsc_control_ui>
   Tsc temperature logger <g4s_deployment/tsc_temperature_logger>


.. toctree::
   :maxdepth: 1
   :caption: g4s deployment tsc bringup:

   Checklist <g4s_deployment/tsc_bringup/checklist>
   Index <g4s_deployment/tsc_bringup/index>


.. toctree::
   :maxdepth: 1
   :caption: g4s deployment wiki:

   Home <g4s_deployment/wiki/Home>


.. toctree::
   :maxdepth: 1
   :caption: lamor15:

   Index <lamor15/index>


.. toctree::
   :maxdepth: 1
   :caption: lamor15 wiki:

   Home <lamor15/wiki/Home>
   Icrai workshop <lamor15/wiki/ICRAI-workshop>
   Individual computer setup <lamor15/wiki/Individual-Computer-Setup>
   Robot vpn to connect from desktop pcs and laptops <lamor15/wiki/Robot-VPN-to-connect-from-Desktop-PCs-and-Laptops>
   Robot configuration <lamor15/wiki/Robot-configuration>
   Tutorial materials 1 <lamor15/wiki/Tutorial-materials-1>
   Tutorial materials 3 <lamor15/wiki/Tutorial-materials-3>
   Tutorial materials 4 <lamor15/wiki/Tutorial-materials-4>
   Vpn to the robot <lamor15/wiki/VPN-to-the-robot>
   Working with the strands robots <lamor15/wiki/Working-with-the-STRANDS-robots>
   Possible tasks <lamor15/wiki/possible-tasks>


.. toctree::
   :maxdepth: 1
   :caption: planning tutorial doc:

   Exercise 1 <planning_tutorial/doc/exercise_1>
   Exercise 2 <planning_tutorial/doc/exercise_2>
   Exercise 3 <planning_tutorial/doc/exercise_3>
   Tutorial prep <planning_tutorial/doc/tutorial_prep>


.. toctree::
   :maxdepth: 1
   :caption: qrobot:

   Index <qrobot/index>


.. toctree::
   :maxdepth: 1
   :caption: robblog:

   Index <robblog/index>


.. toctree::
   :maxdepth: 1
   :caption: scitos 2d navigation:

   Index <scitos_2d_navigation/index>


.. toctree::
   :maxdepth: 1
   :caption: scitos apps:

   Ptu follow frame <scitos_apps/ptu_follow_frame>
   Scitos cmd vel mux <scitos_apps/scitos_cmd_vel_mux>
   Scitos dashboard <scitos_apps/scitos_dashboard>
   Scitos docking <scitos_apps/scitos_docking>
   Scitos teleop <scitos_apps/scitos_teleop>
   Scitos touch <scitos_apps/scitos_touch>


.. toctree::
   :maxdepth: 1
   :caption: scitos apps wiki:

   Home <scitos_apps/wiki/Home>
   Scitos cmd vel mux <scitos_apps/wiki/Scitos-cmd_vel_mux>
   Scitos teleop <scitos_apps/wiki/Scitos-teleop>


.. toctree::
   :maxdepth: 1
   :caption: scitos common:

   Index <scitos_common/index>


.. toctree::
   :maxdepth: 1
   :caption: scitos drivers:

   Scitos bringup <scitos_drivers/scitos_bringup>
   Scitos mira <scitos_drivers/scitos_mira>
   Scitos pc monitor <scitos_drivers/scitos_pc_monitor>


.. toctree::
   :maxdepth: 1
   :caption: scitos robot wiki:

   Bob's network configuration <scitos_robot/wiki/Bob's-Network-Configuration>


.. toctree::
   :maxdepth: 1
   :caption: semantic segmentation:

   Docs <semantic_segmentation/docs>


.. toctree::
   :maxdepth: 1
   :caption: sensortag:

   Index <sensortag/index>


.. toctree::
   :maxdepth: 1
   :caption: soma:

   Index <soma/index>
   Soma llsd <soma/soma_llsd>
   Soma trajectory <soma/soma_trajectory>
   Soma visualizer <soma/soma_visualizer>


.. toctree::
   :maxdepth: 1
   :caption: soma soma utils:

   Config <soma/soma_utils/config>
   Robblog <soma/soma_utils/robblog>


.. toctree::
   :maxdepth: 1
   :caption: strands-docker:

   Index <strands-docker/index>


.. toctree::
   :maxdepth: 1
   :caption: strands 3d mapping:

   Calibrate sweeps <strands_3d_mapping/calibrate_sweeps>
   Cloud merge <strands_3d_mapping/cloud_merge>
   Ekz public lib <strands_3d_mapping/ekz-public-lib>
   Index <strands_3d_mapping/index>
   Learn objects action <strands_3d_mapping/learn_objects_action>
   Metaroom xml parser <strands_3d_mapping/metaroom_xml_parser>
   Nbv planning <strands_3d_mapping/nbv_planning>
   Object manager <strands_3d_mapping/object_manager>
   Object view generator <strands_3d_mapping/object_view_generator>
   Semantic map <strands_3d_mapping/semantic_map>
   Semantic map launcher <strands_3d_mapping/semantic_map_launcher>
   Semantic map publisher <strands_3d_mapping/semantic_map_publisher>
   Semantic map to 2d <strands_3d_mapping/semantic_map_to_2d>


.. toctree::
   :maxdepth: 1
   :caption: strands 3d mapping dynamic object retrieval:

   Index <strands_3d_mapping/dynamic_object_retrieval/index>
   Stopwatch <strands_3d_mapping/dynamic_object_retrieval/stopwatch>


.. toctree::
   :maxdepth: 1
   :caption: strands 3d mapping observation registration:

   Additional view registration server <strands_3d_mapping/observation_registration/additional_view_registration_server>
   Index <strands_3d_mapping/observation_registration/index>
   Observation registration server <strands_3d_mapping/observation_registration/observation_registration_server>
   Observation registration services <strands_3d_mapping/observation_registration/observation_registration_services>
   Siftgpu <strands_3d_mapping/observation_registration/siftgpu>


.. toctree::
   :maxdepth: 1
   :caption: strands 3d mapping quasimodo:

   Index <strands_3d_mapping/quasimodo/index>
   Quasimodo retrieval <strands_3d_mapping/quasimodo/quasimodo_retrieval>


.. toctree::
   :maxdepth: 1
   :caption: strands 3d mapping wiki:

   Get up and running <strands_3d_mapping/wiki/Get-up-and-running>


.. toctree::
   :maxdepth: 1
   :caption: strands apps:

   Marathon reporter <strands_apps/marathon_reporter>
   Odometry mileage <strands_apps/odometry_mileage>
   Roslaunch axserver <strands_apps/roslaunch_axserver>
   Static transform manager <strands_apps/static_transform_manager>
   Watchdog node <strands_apps/watchdog_node>


.. toctree::
   :maxdepth: 1
   :caption: strands data to qsrlib:

   Index <strands_data_to_qsrlib/index>
   Noveltrajectories <strands_data_to_qsrlib/novelTrajectories>


.. toctree::
   :maxdepth: 1
   :caption: strands executive:

   Doc <strands_executive/doc>
   Gcal routine <strands_executive/gcal_routine>
   Index <strands_executive/index>
   Mdp plan exec <strands_executive/mdp_plan_exec>
   Scheduler <strands_executive/scheduler>
   Task executor <strands_executive/task_executor>


.. toctree::
   :maxdepth: 1
   :caption: strands executive behaviours:

   Routine behaviours <strands_executive_behaviours/routine_behaviours>


.. toctree::
   :maxdepth: 1
   :caption: strands exploration:

   Spatiotemporal exploration <strands_exploration/spatiotemporal_exploration>


.. toctree::
   :maxdepth: 1
   :caption: strands hri:

   Strands gazing <strands_hri/strands_gazing>
   Strands human aware navigation <strands_hri/strands_human_aware_navigation>
   Strands human following <strands_hri/strands_human_following>
   Strands visualise speech <strands_hri/strands_visualise_speech>


.. toctree::
   :maxdepth: 1
   :caption: strands morse:

   Bham <strands_morse/bham>
   Index <strands_morse/index>


.. toctree::
   :maxdepth: 1
   :caption: strands morse wiki:

   Bham morse <strands_morse/wiki/BHAM-Morse>
   Morse on ubuntu <strands_morse/wiki/MORSE-on-Ubuntu>


.. toctree::
   :maxdepth: 1
   :caption: strands movebase:

   Calibrate chest <strands_movebase/calibrate_chest>
   Index <strands_movebase/index>


.. toctree::
   :maxdepth: 1
   :caption: strands navigation:

   Message store map switcher <strands_navigation/message_store_map_switcher>
   Monitored navigation <strands_navigation/monitored_navigation>
   Nav goals generator <strands_navigation/nav_goals_generator>
   Topological logging manager <strands_navigation/topological_logging_manager>
   Topological rviz tools <strands_navigation/topological_rviz_tools>


.. toctree::
   :maxdepth: 1
   :caption: strands navigation topological navigation:

   Index <strands_navigation/topological_navigation/index>
   Tests <strands_navigation/topological_navigation/tests>


.. toctree::
   :maxdepth: 1
   :caption: strands navigation wiki:

   Topological map definition <strands_navigation/wiki/Topological-Map-Definition>
   Useful mongodb queries and updates <strands_navigation/wiki/Useful-Mongodb-Queries-and-Updates>


.. toctree::
   :maxdepth: 1
   :caption: strands perception people:

   Bayes people tracker <strands_perception_people/bayes_people_tracker>
   Bayes people tracker logging <strands_perception_people/bayes_people_tracker_logging>
   Detector msg to pose array <strands_perception_people/detector_msg_to_pose_array>
   Ground plane estimation <strands_perception_people/ground_plane_estimation>
   Human trajectory <strands_perception_people/human_trajectory>
   Index <strands_perception_people/index>
   Mdl people tracker <strands_perception_people/mdl_people_tracker>
   Odometry to motion matrix <strands_perception_people/odometry_to_motion_matrix>
   Rwth upper body skeleton random walk <strands_perception_people/rwth_upper_body_skeleton_random_walk>
   Strands head orientation <strands_perception_people/strands_head_orientation>
   Upper body detector <strands_perception_people/upper_body_detector>
   Vision people logging <strands_perception_people/vision_people_logging>
   Wheelchair detector <strands_perception_people/wheelchair_detector>


.. toctree::
   :maxdepth: 1
   :caption: strands perception people opencv warco:

   Libsvm <strands_perception_people/opencv_warco/libsvm>
   Opencv warco <strands_perception_people/opencv_warco/opencv_warco>


.. toctree::
   :maxdepth: 1
   :caption: strands perception people perception people launch:

   Attic <strands_perception_people/perception_people_launch/attic>
   Index <strands_perception_people/perception_people_launch/index>


.. toctree::
   :maxdepth: 1
   :caption: strands perception people visual odometry:

   Fovis <strands_perception_people/visual_odometry/fovis>
   Fv example freenect <strands_perception_people/visual_odometry/fv-example-freenect>
   Fv example openni <strands_perception_people/visual_odometry/fv-example-openni>
   Index <strands_perception_people/visual_odometry/index>


.. toctree::
   :maxdepth: 1
   :caption: strands qsr wiki:

   Data sets <strands_qsr/wiki/Data-sets>
   Evaluation client <strands_qsr/wiki/Evaluation-Client>
   Perception <strands_qsr/wiki/perception>


.. toctree::
   :maxdepth: 1
   :caption: strands qsr lib:

   Docs <strands_qsr_lib/docs>
   Qsr prob rep <strands_qsr_lib/qsr_prob_rep>


.. toctree::
   :maxdepth: 1
   :caption: strands qsr lib qsr lib:

   Data <strands_qsr_lib/qsr_lib/data>
   Index <strands_qsr_lib/qsr_lib/index>


.. toctree::
   :maxdepth: 1
   :caption: strands social:

   Social card reader <strands_social/social_card_reader>
   Strands tweets <strands_social/strands_tweets>


.. toctree::
   :maxdepth: 1
   :caption: strands tabletop perception:

   Index <strands_tabletop_perception/index>
   Mv object classifier <strands_tabletop_perception/mv_object_classifier>
   Object classifier <strands_tabletop_perception/object_classifier>
   Pcd filter <strands_tabletop_perception/pcd_filter>
   Qsr kb <strands_tabletop_perception/qsr_kb>
   Table detection <strands_tabletop_perception/table_detection>
   Visualize pcd indices <strands_tabletop_perception/visualize_pcd_indices>


.. toctree::
   :maxdepth: 1
   :caption: strands ui:

   Index <strands_ui/index>
   Mary tts <strands_ui/mary_tts>
   Mongodb media server <strands_ui/mongodb_media_server>
   Robot talk <strands_ui/robot_talk>
   Strands webserver <strands_ui/strands_webserver>


.. toctree::
   :maxdepth: 1
   :caption: thermo fisher:

   Map <thermo_fisher/map>


.. toctree::
   :maxdepth: 1
   :caption: trajectory behaviours:

   Human trajectory classifier <trajectory_behaviours/human_trajectory_classifier>
   Relational learner <trajectory_behaviours/relational_learner>


.. toctree::
   :maxdepth: 1
   :caption: v4r:

   Objectrecognizer <v4r/ObjectRecognizer>
   Citation <v4r/citation>
   Contributing <v4r/contributing>
   Index <v4r/index>
   Ml <v4r/ml>
   Opennurbs <v4r/opennurbs>


.. toctree::
   :maxdepth: 1
   :caption: v4r docs:

   Imkrecognizer <v4r/docs/imkrecognizer>
   Objectclassification <v4r/docs/objectclassification>
   Objectdetection <v4r/docs/objectdetection>
   Objectmodeling <v4r/docs/objectmodeling>
   V4r style guide <v4r/docs/v4r_style_guide>


.. toctree::
   :maxdepth: 1
   :caption: v4r ros wrappers:

   Contributing <v4r_ros_wrappers/contributing>
   Index <v4r_ros_wrappers/index>
   Multiview object recognizer <v4r_ros_wrappers/multiview_object_recognizer>
   Object classifier <v4r_ros_wrappers/object_classifier>
   Object gestalt segmentation <v4r_ros_wrappers/object_gestalt_segmentation>
   Singleview object recognizer <v4r_ros_wrappers/singleview_object_recognizer>
   Tutorial <v4r_ros_wrappers/tutorial>


